
      "ðŸ“Š Epoch Summary Table\n",
      "Epoch | Mean Val Dice\n",
      "----------------------\n",
      "    1 | 0.1678\n",
      "    2 | 0.7489\n",
      "    3 | 0.8919\n",
      "    4 | 0.9359\n",
      "    5 | 0.9565\n",
      "    6 | 0.9870\n",
      "    7 | 0.9843\n",
      "    8 | 0.9909\n",
      "    9 | 0.9909\n",
      "   10 | 0.9902\n",
      "   11 | 0.9919\n",
      "   12 | 0.9904\n",
      "   13 | 0.9923\n",
      "   14 | 0.9928\n",
      "   15 | 0.9936\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    " Training script\n",
    "\n",
    "\n",
    "import os, re, time, random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# -------------------------\n",
    "# REPRODUCIBILITY\n",
    "# -------------------------\n",
    "SEED = int(os.environ.get(\"SEED\", \"42\"))\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG (DO NOT HARD-CODE PRIVATE PATHS)\n",
    "# Set as environment variables when running:\n",
    "#   export CT_DIR=/path/to/ct\n",
    "#   export MASK_DIR=/path/to/masks\n",
    "# -------------------------\n",
    "CT_DIR = os.environ.get(\"CT_DIR\", \"./data/ct_mat\")\n",
    "MASK_DIR = os.environ.get(\"MASK_DIR\", \"./data/masks_mat\")\n",
    "\n",
    "OUT_SHAPE = tuple(map(int, os.environ.get(\"OUT_SHAPE\", \"128,128,128\").split(\",\")))\n",
    "EPOCHS = int(os.environ.get(\"EPOCHS\", \"15\"))\n",
    "BATCH_SIZE = int(os.environ.get(\"BATCH_SIZE\", \"1\"))\n",
    "LR = float(os.environ.get(\"LR\", \"1e-3\"))\n",
    "TRAIN_SPLIT = float(os.environ.get(\"TRAIN_SPLIT\", \"0.9\"))\n",
    "OUT_DIR = os.environ.get(\"OUT_DIR\", \"./outputs\")\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# -------------------------\n",
    "# DATASET\n",
    "# -------------------------\n",
    "def extract_field(mat_entry, field):\n",
    "    return mat_entry[0, 0][field]\n",
    "\n",
    "class LungMatDataset(Dataset):\n",
    "    def __init__(self, ct_dir, mask_dir, out_shape=(128,128,128)):\n",
    "        self.out_shape = out_shape\n",
    "        self.pairs = []\n",
    "\n",
    "        if not os.path.isdir(ct_dir):\n",
    "            raise FileNotFoundError(f\"CT_DIR not found: {ct_dir}\")\n",
    "        if not os.path.isdir(mask_dir):\n",
    "            raise FileNotFoundError(f\"MASK_DIR not found: {mask_dir}\")\n",
    "\n",
    "        for f in sorted(os.listdir(ct_dir)):\n",
    "            if not f.endswith(\".mat\"):\n",
    "                continue\n",
    "            pid_match = re.findall(r\"BRUCI\\d+\", f)\n",
    "            if not pid_match:\n",
    "                continue\n",
    "            pid = pid_match[0]\n",
    "            ct_file = os.path.join(ct_dir, f)\n",
    "            mask_file = os.path.join(mask_dir, f\"{pid}_LungMasks_ALUK.mat\")\n",
    "            if os.path.exists(mask_file):\n",
    "                self.pairs.append((ct_file, mask_file))\n",
    "\n",
    "        print(f\"Found {len(self.pairs)} matched cases.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        ct_path, mask_path = self.pairs[idx]\n",
    "\n",
    "        ct = extract_field(loadmat(ct_path)[\"imagingData\"], \"dataVolume\")\n",
    "        left = extract_field(loadmat(mask_path)[\"lungMasks\"], \"leftLung\")\n",
    "        right = extract_field(loadmat(mask_path)[\"lungMasks\"], \"rightLung\")\n",
    "\n",
    "        mask = np.zeros_like(left, dtype=np.uint8)\n",
    "        mask[left == 1] = 1\n",
    "        mask[right == 1] = 2\n",
    "\n",
    "        ct = torch.tensor(ct).float().unsqueeze(0).unsqueeze(0)      # (1,1,D,H,W)\n",
    "        mask = torch.tensor(mask).long().unsqueeze(0).unsqueeze(0)   # (1,1,D,H,W)\n",
    "\n",
    "        ct = F.interpolate(ct, self.out_shape, mode=\"trilinear\", align_corners=False)\n",
    "        mask = F.interpolate(mask.float(), self.out_shape, mode=\"nearest\").long()\n",
    "\n",
    "        # z-score normalisation (per-volume)\n",
    "        ct = (ct - ct.mean()) / (ct.std() + 1e-6)\n",
    "\n",
    "        return ct[0], mask[0, 0]  # (1,D,H,W), (D,H,W)\n",
    "\n",
    "# -------------------------\n",
    "# SINUSOIDAL POSITIONAL ENCODING \n",
    "# -------------------------\n",
    "def sine_encoding(x, num_bands=6, base_list=(0.5, 1.0, 2.0)):\n",
    "    b, c, d, h, w = x.shape\n",
    "    z = torch.linspace(-1, 1, d, device=x.device).view(1, d, 1, 1).expand(b, d, h, w)\n",
    "    y = torch.linspace(-1, 1, h, device=x.device).view(1, 1, h, 1).expand(b, d, h, w)\n",
    "    x_ = torch.linspace(-1, 1, w, device=x.device).view(1, 1, 1, w).expand(b, d, h, w)\n",
    "\n",
    "    enc = []\n",
    "    for base in base_list:\n",
    "        for freq in range(num_bands):\n",
    "            scale = base * (2.0 ** freq) * np.pi\n",
    "            for fn in (torch.sin, torch.cos):\n",
    "                enc.append(fn(scale * x_))\n",
    "                enc.append(fn(scale * y))\n",
    "                enc.append(fn(scale * z))\n",
    "\n",
    "    pos = torch.stack(enc, dim=1)  # (b, Cpos, d, h, w)\n",
    "\n",
    "    # Match channels to input channels\n",
    "    if pos.shape[1] >= c:\n",
    "        pos = pos[:, :c]\n",
    "    else:\n",
    "        pos = F.pad(pos, (0,0,0,0,0,0,0, c - pos.shape[1]))\n",
    "\n",
    "    return x + pos\n",
    "\n",
    "# -------------------------\n",
    "# MODEL \n",
    "# -------------------------\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class UNet3DDeep(nn.Module):\n",
    "    def __init__(self, in_ch=1, out_ch=3):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool3d(2)\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = DoubleConv(in_ch, 32)\n",
    "        self.enc2 = DoubleConv(32, 64)\n",
    "        self.enc3 = DoubleConv(64, 128)\n",
    "        self.enc4 = DoubleConv(128, 256)\n",
    "\n",
    "        # Bottleneck (C=512)\n",
    "        self.bottleneck = DoubleConv(256, 512)\n",
    "\n",
    "        # Decoder\n",
    "        self.up4 = nn.ConvTranspose3d(512, 256, 2, stride=2)\n",
    "        self.dec4 = DoubleConv(256 + 256, 256)\n",
    "\n",
    "        self.up3 = nn.ConvTranspose3d(256, 128, 2, stride=2)\n",
    "        self.dec3 = DoubleConv(128 + 128, 128)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose3d(128, 64, 2, stride=2)\n",
    "        self.dec2 = DoubleConv(64 + 64, 64)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose3d(64, 32, 2, stride=2)\n",
    "        self.dec1 = DoubleConv(32 + 32, 32)\n",
    "\n",
    "        self.out = nn.Conv3d(32, out_ch, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # positional encoding at input\n",
    "        x = sine_encoding(x, num_bands=6, base_list=(0.5, 1.0, 2.0))\n",
    "\n",
    "        e1 = self.enc1(x)              # 32\n",
    "        e2 = self.enc2(self.pool(e1))  # 64\n",
    "        e3 = self.enc3(self.pool(e2))  # 128\n",
    "        e4 = self.enc4(self.pool(e3))  # 256\n",
    "\n",
    "        b  = self.bottleneck(self.pool(e4))  # 512\n",
    "\n",
    "        d4 = self.up4(b)\n",
    "        d4 = self.dec4(torch.cat([d4, e4], dim=1))  # 256\n",
    "\n",
    "        d3 = self.up3(d4)\n",
    "        d3 = self.dec3(torch.cat([d3, e3], dim=1))  # 128\n",
    "\n",
    "        d2 = self.up2(d3)\n",
    "        d2 = self.dec2(torch.cat([d2, e2], dim=1))  # 64\n",
    "\n",
    "        d1 = self.up1(d2)\n",
    "        d1 = self.dec1(torch.cat([d1, e1], dim=1))  # 32\n",
    "\n",
    "        return self.out(d1)\n",
    "\n",
    "# -------------------------\n",
    "# LOSS + METRIC (LEFT/RIGHT CLASSES 1..2)\n",
    "# -------------------------\n",
    "class DiceCELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        ce = self.ce(logits, target)\n",
    "\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        dice = 0.0\n",
    "        for c in (1, 2):\n",
    "            p = probs[:, c]\n",
    "            t = (target == c).float()\n",
    "            inter = (p * t).sum()\n",
    "            union = p.sum() + t.sum()\n",
    "            dice += 1.0 - (2.0 * inter + 1e-6) / (union + 1e-6)\n",
    "\n",
    "        return ce + dice\n",
    "\n",
    "@torch.no_grad()\n",
    "def mean_dice(logits, target):\n",
    "    pred = torch.argmax(F.softmax(logits, dim=1), dim=1)\n",
    "    scores = []\n",
    "    for c in (1, 2):\n",
    "        p = (pred == c).float()\n",
    "        t = (target == c).float()\n",
    "        inter = (p * t).sum()\n",
    "        union = p.sum() + t.sum()\n",
    "        scores.append((2.0 * inter / (union + 1e-6)).item())\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "# -------------------------\n",
    "# TRAIN / VAL\n",
    "# -------------------------\n",
    "ds = LungMatDataset(CT_DIR, MASK_DIR, out_shape=OUT_SHAPE)\n",
    "if len(ds) < 2:\n",
    "    raise RuntimeError(\"Need at least 2 cases to split train/val.\")\n",
    "\n",
    "train_len = int(TRAIN_SPLIT * len(ds))\n",
    "train_ds = torch.utils.data.Subset(ds, range(train_len))\n",
    "val_ds = torch.utils.data.Subset(ds, range(train_len, len(ds)))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "model = UNet3DDeep(in_ch=1, out_ch=3).to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = DiceCELoss()\n",
    "\n",
    "best_val = -1.0\n",
    "epoch_log = []\n",
    "t0 = time.time()\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "\n",
    "    for ct, mask in train_loader:\n",
    "        ct, mask = ct.to(device), mask.to(device)\n",
    "\n",
    "        logits = model(ct)\n",
    "        loss = loss_fn(logits, mask)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    vals = []\n",
    "    for ct, mask in val_loader:\n",
    "        ct, mask = ct.to(device), mask.to(device)\n",
    "        logits = model(ct)\n",
    "        vals.append(mean_dice(logits, mask))\n",
    "\n",
    "    mean_val = float(np.mean(vals)) if len(vals) else 0.0\n",
    "    mean_train_loss = running / max(1, len(train_loader))\n",
    "\n",
    "    print(f\"Epoch {epoch:02d}/{EPOCHS} | train loss {mean_train_loss:.4f} | val dice {mean_val:.4f}\")\n",
    "    epoch_log.append((epoch, mean_train_loss, mean_val))\n",
    "\n",
    "    # Save best model only (journal/GitHub friendly)\n",
    "    if mean_val > best_val:\n",
    "        best_val = mean_val\n",
    "        torch.save(model.state_dict(), os.path.join(OUT_DIR, \"model_best.pth\"))\n",
    "\n",
    "# Save a simple CSV log\n",
    "log_path = os.path.join(OUT_DIR, \"epoch_log.csv\")\n",
    "with open(log_path, \"w\") as f:\n",
    "    f.write(\"epoch,train_loss,val_dice\\n\")\n",
    "    for ep, tr, vd in epoch_log:\n",
    "        f.write(f\"{ep},{tr:.6f},{vd:.6f}\\n\")\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f\"\\nDone. Best val dice: {best_val:.4f}\")\n",
    "print(f\"Outputs saved to: {OUT_DIR}\")\n",
    "print(f\"Log: {log_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5de8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# ==========================================================\n",
    "# GENERIC OVERLAY VISUALISATION \n",
    "# ==========================================================\n",
    "\n",
    "# ---- Default Path ----\n",
    "IMAGE_DIR = os.environ.get(\"IMAGE_DIR\", \"./overlay_images\")\n",
    "\n",
    "if not os.path.exists(IMAGE_DIR):\n",
    "    raise FileNotFoundError(f\"Image directory not found: {IMAGE_DIR}\")\n",
    "\n",
    "# ---- Automatically collect unique case prefixes ----\n",
    "files = [f for f in os.listdir(IMAGE_DIR) if f.endswith(\".png\") and \"_epoch\" in f]\n",
    "case_prefixes = sorted(set(f.split(\"_epoch\")[0] for f in files))\n",
    "\n",
    "if len(case_prefixes) == 0:\n",
    "    raise RuntimeError(\"No overlay images found in directory.\")\n",
    "\n",
    "# ---- Automatically collect unique epochs ----\n",
    "epoch_labels = sorted(set(f.split(\"_epoch\")[1].split(\".\")[0] for f in files))\n",
    "\n",
    "# ---- Plot Setup ----\n",
    "rows = len(case_prefixes)\n",
    "cols = len(epoch_labels) * 3\n",
    "\n",
    "fig, axs = plt.subplots(rows, cols, figsize=(5 * len(epoch_labels) * 3, 4 * rows))\n",
    "\n",
    "if rows == 1:\n",
    "    axs = [axs]\n",
    "\n",
    "for i, case_name in enumerate(case_prefixes):\n",
    "    for j, epoch_label in enumerate(epoch_labels):\n",
    "\n",
    "        img_path = os.path.join(IMAGE_DIR, f\"{case_name}_epoch{epoch_label}.png\")\n",
    "        col_base = j * 3\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            for k in range(3):\n",
    "                axs[i][col_base + k].axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        img = mpimg.imread(img_path)\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        w_split = w // 3\n",
    "\n",
    "        ct_img = img[:, :w_split]\n",
    "        gt_img = img[:, w_split:2*w_split]\n",
    "        pred_img = img[:, 2*w_split:]\n",
    "\n",
    "        # CT\n",
    "        axs[i][col_base].imshow(ct_img)\n",
    "        axs[i][col_base].set_title(f\"{case_name} | epoch {epoch_label} | CT\")\n",
    "        axs[i][col_base].axis(\"off\")\n",
    "\n",
    "        # GT\n",
    "        axs[i][col_base + 1].imshow(gt_img)\n",
    "        axs[i][col_base + 1].set_title(\"Ground Truth\")\n",
    "        axs[i][col_base + 1].axis(\"off\")\n",
    "\n",
    "        # Prediction\n",
    "        axs[i][col_base + 2].imshow(pred_img)\n",
    "        axs[i][col_base + 2].set_title(\"Prediction\")\n",
    "        axs[i][col_base + 2].axis(\"off\")\n",
    "\n",
    "red_patch = mpatches.Patch(color=\"red\", label=\"Left Lung\")\n",
    "green_patch = mpatches.Patch(color=\"green\", label=\"Right Lung\")\n",
    "fig.legend(handles=[red_patch, green_patch],\n",
    "           loc=\"lower center\",\n",
    "           bbox_to_anchor=(0.5, -0.02),\n",
    "           ncol=2)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.04, 1, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab2d9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef0e10d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d39c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce69a562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d46797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae5ed49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
